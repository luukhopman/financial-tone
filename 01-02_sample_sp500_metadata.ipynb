{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample - Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = '01-02_sample_sp500_metadata'\n",
    "PROJECT = 'conference-calls-sentiment'\n",
    "PYTHON_VERSION = '3.7.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logging\n",
    "from utils import log_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = re.sub(\"(?<={})[\\w\\W]*\".format(PROJECT), \"\", os.getcwd())\r\n",
    "os.chdir(workdir)\r\n",
    "\r\n",
    "pipeline = os.path.join('2_pipeline', NAME)\r\n",
    "if not os.path.exists(pipeline):\r\n",
    "    os.makedirs(pipeline)\r\n",
    "    for folder in ['out', 'store', 'tmp']:\r\n",
    "        os.makedirs(os.path.join(pipeline, folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_PATH = os.path.join('0_data', 'conference_calls_transcripts', 'metadata.csv')\r\n",
    "metadata = pd.read_csv(METADATA_PATH, sep='\\t', engine='python')\r\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_step\r\n",
    "def start_pipeline(metadata):\r\n",
    "    return metadata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_step\r\n",
    "def handle_dates(metadata):\r\n",
    "    metadata['event_date'] = pd.to_datetime(metadata['event_date'], format=r'%d-%b-%Y')\r\n",
    "    metadata['year'] = metadata['event_date'].dt.year\r\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_step\r\n",
    "def filter_sp500_firms(metadata):\r\n",
    "    SP500_PATH = os.path.join('2_pipeline', '01-01_sample_sp500_constituents', 'out', 'sp500_consituents_2000-2020.feather')\r\n",
    "    sp500 = pd.read_feather(SP500_PATH)\r\n",
    "\r\n",
    "    metadata_sp500 = metadata.merge(sp500, on='gvkey')\r\n",
    "\r\n",
    "    in_sp500 = metadata_sp500['event_date'].between(metadata_sp500['start_date'], metadata_sp500['end_date'])\r\n",
    "    metadata_sp500 = metadata_sp500[in_sp500]\r\n",
    "    \r\n",
    "    return metadata_sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_step\r\n",
    "def filter_earnings_calls(metadata):\r\n",
    "    earning_dates = pd.read_csv(os.path.join('0_data', 'sp500_constituents', 'sp500_quarterly-earnings_2000-2020.csv'))\r\n",
    "    \r\n",
    "    earning_dates['event_date'] = pd.to_datetime(earning_dates['rdq'], format=r'%Y%m%d')\r\n",
    "    earning_dates = earning_dates[['gvkey', 'event_date']].drop_duplicates()\r\n",
    "\r\n",
    "    sp500_earnings = metadata.merge(earning_dates, on=['gvkey', 'event_date'], validate='m:1')\r\n",
    "\r\n",
    "    # Drop duplicates if there are multiple conference calls on one day\r\n",
    "    sp500_earnings = sp500_earnings.drop_duplicates(['gvkey', 'event_date']).reset_index()\r\n",
    "    return sp500_earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript_id_mapping(path):\r\n",
    "    filepaths = []\r\n",
    "    for year in os.listdir(path):\r\n",
    "        year_path = os.path.join(path, year)\r\n",
    "        if os.path.isdir(year_path):\r\n",
    "            filenames = os.listdir(year_path)\r\n",
    "            for filename in filenames:\r\n",
    "                filepaths.append(os.path.join(year, filename))\r\n",
    "\r\n",
    "    transcript_ids = [int(f.split('-')[-2]) for f in filepaths]\r\n",
    "    return {k:v for k, v in zip(transcript_ids, filepaths)}\r\n",
    "\r\n",
    "@log_step\r\n",
    "def add_filepaths(metadata):\r\n",
    "    TRANSCRIPTS_PATH = os.path.join('0_data', 'conference_calls_transcripts')\r\n",
    "    transcript_id_mapping = get_transcript_id_mapping(TRANSCRIPTS_PATH)\r\n",
    "    metadata['filepath'] = metadata['transcript_id'].apply(lambda x: transcript_id_mapping.get(x, np.nan))\r\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_step\r\n",
    "def clean_metadata(metadata):\r\n",
    "    columns = ['gvkey', 'coname', 'event_date', 'event_name', 'event_time',\r\n",
    "               'event_type', 'transcript_id', 'filepath', 'year',\r\n",
    "               'cik', 'ticker', 'regcountrycode']\r\n",
    "    \r\n",
    "    metadata_clean = (metadata[columns]\r\n",
    "                      .copy()\r\n",
    "                      .rename(columns={'regcountrycode': 'country'})\r\n",
    "                      .assign(gvkey=lambda x: x['gvkey'].astype('int'),\r\n",
    "                              year=lambda x: x['year'].astype('int'))\r\n",
    "                      .query('2004 <= year <= 2020')\r\n",
    "                      .sort_values(['gvkey', 'event_date'])\r\n",
    "                      .reset_index(drop=True))\r\n",
    "    return metadata_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start_pipeline] nrows=351,851 ncols=32\n",
      "[handle_dates] nrows=351,851 ncols=33\n",
      "[filter_sp500_firms] nrows=37,418 ncols=39\n",
      "[filter_earnings_calls] nrows=29,365 ncols=40\n",
      "[add_filepaths] nrows=29,365 ncols=41\n",
      "[clean_metadata] nrows=26,651 ncols=12\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gvkey</th>\n      <th>coname</th>\n      <th>event_date</th>\n      <th>event_name</th>\n      <th>event_time</th>\n      <th>event_type</th>\n      <th>transcript_id</th>\n      <th>filepath</th>\n      <th>year</th>\n      <th>cik</th>\n      <th>ticker</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1013</td>\n      <td>ADC TELECOMMUNICATIONS INC</td>\n      <td>2004-02-18</td>\n      <td>Q1 2004 ADC Earnings Conference Call</td>\n      <td>17:00</td>\n      <td>Earnings Conference Call</td>\n      <td>137638020605</td>\n      <td>2004\\2004-Feb-18-ADCT.OQ^L10-137638020605-Tran...</td>\n      <td>2004</td>\n      <td>61478.0</td>\n      <td>ADCT</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1013</td>\n      <td>ADC TELECOMMUNICATIONS INC</td>\n      <td>2004-05-19</td>\n      <td>Q2 2004 ADC Earnings Conference Call</td>\n      <td>17:00</td>\n      <td>Earnings Conference Call</td>\n      <td>138206702539</td>\n      <td>2004\\2004-May-19-ADCT.OQ^L10-138206702539-Tran...</td>\n      <td>2004</td>\n      <td>61478.0</td>\n      <td>ADCT</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1013</td>\n      <td>ADC TELECOMMUNICATIONS INC</td>\n      <td>2004-08-25</td>\n      <td>Q3 2004 ADC Earnings Conference Call</td>\n      <td>17:00</td>\n      <td>Earnings Conference Call</td>\n      <td>137720754281</td>\n      <td>2004\\2004-Aug-25-ADCT.OQ^L10-137720754281-Tran...</td>\n      <td>2004</td>\n      <td>61478.0</td>\n      <td>ADCT</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1013</td>\n      <td>ADC TELECOMMUNICATIONS INC</td>\n      <td>2004-12-14</td>\n      <td>Q4 2004 ADC Earnings Conference Call</td>\n      <td>17:00</td>\n      <td>Earnings Conference Call</td>\n      <td>138829529879</td>\n      <td>2004\\2004-Dec-14-ADCT.OQ^L10-138829529879-Tran...</td>\n      <td>2004</td>\n      <td>61478.0</td>\n      <td>ADCT</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1013</td>\n      <td>ADC TELECOMMUNICATIONS INC</td>\n      <td>2005-02-28</td>\n      <td>Q1 2005 ADC Earnings Conference Call</td>\n      <td>17:00</td>\n      <td>Earnings Conference Call</td>\n      <td>139950184137</td>\n      <td>2005\\2005-Feb-28-ADCT.OQ^L10-139950184137-Tran...</td>\n      <td>2005</td>\n      <td>61478.0</td>\n      <td>ADCT</td>\n      <td>US</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   gvkey                      coname event_date  \\\n0   1013  ADC TELECOMMUNICATIONS INC 2004-02-18   \n1   1013  ADC TELECOMMUNICATIONS INC 2004-05-19   \n2   1013  ADC TELECOMMUNICATIONS INC 2004-08-25   \n3   1013  ADC TELECOMMUNICATIONS INC 2004-12-14   \n4   1013  ADC TELECOMMUNICATIONS INC 2005-02-28   \n\n                             event_name event_time                event_type  \\\n0  Q1 2004 ADC Earnings Conference Call      17:00  Earnings Conference Call   \n1  Q2 2004 ADC Earnings Conference Call      17:00  Earnings Conference Call   \n2  Q3 2004 ADC Earnings Conference Call      17:00  Earnings Conference Call   \n3  Q4 2004 ADC Earnings Conference Call      17:00  Earnings Conference Call   \n4  Q1 2005 ADC Earnings Conference Call      17:00  Earnings Conference Call   \n\n   transcript_id                                           filepath  year  \\\n0   137638020605  2004\\2004-Feb-18-ADCT.OQ^L10-137638020605-Tran...  2004   \n1   138206702539  2004\\2004-May-19-ADCT.OQ^L10-138206702539-Tran...  2004   \n2   137720754281  2004\\2004-Aug-25-ADCT.OQ^L10-137720754281-Tran...  2004   \n3   138829529879  2004\\2004-Dec-14-ADCT.OQ^L10-138829529879-Tran...  2004   \n4   139950184137  2005\\2005-Feb-28-ADCT.OQ^L10-139950184137-Tran...  2005   \n\n       cik ticker country  \n0  61478.0   ADCT      US  \n1  61478.0   ADCT      US  \n2  61478.0   ADCT      US  \n3  61478.0   ADCT      US  \n4  61478.0   ADCT      US  "
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_metadata = (metadata.pipe(start_pipeline)\r\n",
    "                           .pipe(handle_dates)\r\n",
    "                           .pipe(filter_sp500_firms)\r\n",
    "                           .pipe(filter_earnings_calls)\r\n",
    "                           .pipe(add_filepaths)\r\n",
    "                           .pipe(clean_metadata))\r\n",
    "sample_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_metadata.to_feather(os.path.join(pipeline, 'out', 'sample_metadata.feather'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ad8bff83ca7a203c8f5c1f2f3a00576dbcaaca98e752b3367803050219b2dc1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('ccs': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}