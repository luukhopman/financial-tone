{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conference Calls - Parse txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = '02-01_conference_calls_parse_txt'\r\n",
    "PROJECT = 'conference-calls-sentiment'\r\n",
    "PYTHON_VERSION = '3.7.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = re.sub(\"(?<={})[\\w\\W]*\".format(PROJECT), \"\", os.getcwd())\r\n",
    "os.chdir(workdir)\r\n",
    "\r\n",
    "pipeline = os.path.join('2_pipeline', NAME)\r\n",
    "if not os.path.exists(pipeline):\r\n",
    "    os.makedirs(pipeline)\r\n",
    "    for folder in ['out', 'store', 'tmp']:\r\n",
    "        os.makedirs(os.path.join(pipeline, folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Main Code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read transcript metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_PATH = os.path.join('2_pipeline', '01-02_sample_sp500_metadata', 'out', 'sample_metadata.feather')\r\n",
    "sp500_transcripts = pd.read_feather(METADATA_PATH)\r\n",
    "sp500_transcripts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_PATH = os.path.join('0_data', 'conference_calls_transcripts')\n",
    "\n",
    "def read_transcript(file_path):\n",
    "    with open(os.path.join(TRANSCRIPTS_PATH, file_path), encoding='utf-8') as f:\n",
    "        transcript = f.read()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_transcript(transcript):      \r\n",
    "    pres_pattern = re.compile(\"Presentation(.*?)Questions and Answers\", flags=re.DOTALL)\r\n",
    "    try:\r\n",
    "        presentation = pres_pattern.search(transcript).group(1)\r\n",
    "    except AttributeError:\r\n",
    "        raise AttributeError('No Questions and Answers')\r\n",
    "\r\n",
    "    ques_pattern = re.compile(\"Questions and Answers(.*?)Definitions\", flags=re.DOTALL)\r\n",
    "    questions = ques_pattern.search(transcript).group(1)\r\n",
    "    return presentation, questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_speakers(transcript):   \r\n",
    "    speech_pattern = re.compile(\"--\\n(.*?)\\n[-=]{2}\", flags=re.DOTALL)\r\n",
    "    matches = [i.group(1) for i in speech_pattern.finditer(transcript)]\r\n",
    "    \r\n",
    "    speakers = matches[0::2]\r\n",
    "    spoken_text = matches[1::2]\r\n",
    "    return speakers, spoken_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_id(speaker):\n",
    "    speaker_id_pattern = re.compile(r\"\\[([0-9]+)\\]\")\n",
    "    speaker_id = speaker_id_pattern.search(speaker)\n",
    "    return speaker_id.group(1)\n",
    "\n",
    "def get_speaker_name(speaker):\n",
    "    if ',' in speaker:\n",
    "        return speaker.split(',')[0].strip()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def get_speaker_firm(speaker):\n",
    "    if ',' in speaker:\n",
    "        return speaker.split(',')[1].split('-')[0].strip()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def get_speaker_role(speaker):\n",
    "    if '-' in speaker:\n",
    "        speaker_role = speaker.split('-')[-1]\n",
    "    else:\n",
    "        speaker_role = speaker\n",
    "    return speaker_role.split('[')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcript(filepath):\r\n",
    "    section_names = {0: 'Presentation', 1: 'Questions and Answers'}\r\n",
    "\r\n",
    "    transcript = read_transcript(filepath)\r\n",
    "    presentation, questions = parse_transcript(transcript)\r\n",
    "\r\n",
    "    parsed_transcript = pd.DataFrame(columns=['speaker_id', 'speaker_name', 'speaker_firm', 'speaker_role',\r\n",
    "                                              'transcript', 'section_name', 'filepath'])\r\n",
    "    for section_id, section in enumerate([presentation, questions]):\r\n",
    "        speakers, spoken_text = parse_speakers(section)\r\n",
    "\r\n",
    "        for speaker, text in zip(speakers, spoken_text):\r\n",
    "            # Parse speaker information\r\n",
    "            speaker_id = get_speaker_id(speaker)\r\n",
    "            speaker_name = get_speaker_name(speaker)\r\n",
    "            speaker_firm = get_speaker_firm(speaker)\r\n",
    "            speaker_role = get_speaker_role(speaker)\r\n",
    "\r\n",
    "            # Identify section (Presentation or Questions and Answers)\r\n",
    "            section_name = section_names[section_id]\r\n",
    "\r\n",
    "            # Append data to DataFrame\r\n",
    "            data = [speaker_id, speaker_name, speaker_firm, speaker_role, text, section_name, filepath]\r\n",
    "            parsed_transcript.loc[len(parsed_transcript)] = data\r\n",
    "\r\n",
    "    return parsed_transcript\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse all transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_from_filepaths(filepaths):\r\n",
    "    # Log errors\r\n",
    "    logging.basicConfig(filename=os.path.join(pipeline, 'store', 'errors.log'), filemode='w')\r\n",
    "\r\n",
    "    # Create empty DataFrame\r\n",
    "    parsed_transcripts = pd.DataFrame()\r\n",
    "    for filepath in tqdm(filepaths):\r\n",
    "        try: \r\n",
    "            # Parse data and append to DataFrame\r\n",
    "            parsed_transcript = process_transcript(filepath)\r\n",
    "            parsed_transcripts = pd.concat([parsed_transcripts, parsed_transcript])\r\n",
    "        except AttributeError as e:\r\n",
    "            logging.warning(f'{filepath} - {e}')\r\n",
    "    return parsed_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26651/26651 [3:49:57<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "parsed_transcripts = parse_from_filepaths(sp500_transcripts['filepath'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_transcripts_metadata = parsed_transcripts.merge(sp500_transcripts, on='filepath', validate='m:1')\r\n",
    "parsed_transcripts_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_transcripts_metadata.to_feather(os.path.join(pipeline, 'out', 'cc_transcripts_parsed.feather'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ad8bff83ca7a203c8f5c1f2f3a00576dbcaaca98e752b3367803050219b2dc1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('ccs': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}