{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyst Recommendations\r\n",
    "*[Source](https://wrds-web.wharton.upenn.edu/wrds//ds/ibes/recddet/index.cfm)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = '06-01_analysts_recommendations'\r\n",
    "PROJECT = 'conference-calls-sentiment'\r\n",
    "PYTHON_VERSION = '3.7.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import re\r\n",
    "import numpy as np\r\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = re.sub(\"(?<={})[\\w\\W]*\".format(PROJECT), \"\", os.getcwd())\r\n",
    "os.chdir(workdir)\r\n",
    "\r\n",
    "pipeline = os.path.join('2_pipeline', NAME)\r\n",
    "if not os.path.exists(pipeline):\r\n",
    "    os.makedirs(pipeline)\r\n",
    "    for folder in ['out', 'store', 'tmp']:\r\n",
    "        os.makedirs(os.path.join(pipeline, folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Main Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {'OFTIC': 'ticker', 'TICKER': 'ibes_ticker', 'CNAME': 'coname',\r\n",
    "        'ESTIMID': 'brokerage', 'ANALYST': 'analyst', 'IRECCD': 'rating',\r\n",
    "        'EMASKCD': 'brokerage_id', 'AMASKCD': 'analyst_id',\r\n",
    "        'ANNDATS': 'date', 'ANNTIMS': 'time'}\r\n",
    "\r\n",
    "recommendations_raw = pd.read_csv(os.path.join('0_data', 'ibes', 'ibes_recommendations_2000-2020.csv.gz'), usecols=cols, encoding='latin-1')\r\n",
    "\r\n",
    "recommendations_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation\r\n",
    "*Ratings (`rating`):*\r\n",
    "\r\n",
    "*1. Strong Buy;*\r\n",
    "*2. Buy;*\r\n",
    "*3. Hold;*\r\n",
    "*4. Underperform;*\r\n",
    "*5. Sell*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_previous_valuation(df):\r\n",
    "    df[['prev_rating', 'prev_date']] = df.groupby(['ticker', 'brokerage', 'analyst'])[['rating', 'date']].shift(1)\r\n",
    "    df['days_since_prev'] = df['date'] - df['prev_date']\r\n",
    "    df['rating_change'] = -(df['rating'] - df['prev_rating'])  # Lower rating is better\r\n",
    "    df['rating_sentiment'] = np.where(df['rating_change'] > 0, 1, -1)\r\n",
    "    df['rating_sentiment'] = np.where(df['rating_change'] == 0, 0, df['rating_sentiment'])\r\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = (recommendations_raw\r\n",
    "                   .copy()\r\n",
    "                   .dropna()\r\n",
    "                   .rename(columns=cols)\r\n",
    "                   .assign(\r\n",
    "                       date=lambda x: pd.to_datetime(x['date'], format=r'%Y%m%d'),\r\n",
    "                       analyst=lambda x: x['analyst'].apply(lambda a: ' '.join(a.split()))  # Remove extra whitespaces between analyst names\r\n",
    "                       )\r\n",
    "                   .sort_values(['ticker', 'analyst_id', 'date', 'time'])\r\n",
    "                   .drop_duplicates(['ticker', 'analyst_id', 'date'])\r\n",
    "                   .pipe(add_previous_valuation)\r\n",
    "                   .dropna()\r\n",
    "                   .reset_index(drop=True)\r\n",
    "                   .filter(['ticker', 'coname', 'brokerage', 'brokarage_id',\r\n",
    "                            'analyst', 'analyst_id', 'date', 'days_since_prev',\r\n",
    "                            'prev_rating', 'rating', 'rating_change', 'rating_sentiment']))\r\n",
    "\r\n",
    "recommendations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-1.0    28157\n 1.0    25661\n-0.0    23552\n-2.0    13455\n 2.0    12618\n-3.0      351\n 3.0      291\n-4.0      204\n 4.0      189\nName: rating_change, dtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations['rating_change'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-1    42167\n 1    38759\n 0    23552\nName: rating_sentiment, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations['rating_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save `analyst_id`-`analyst` mapping\r\n",
    "*I/B/E/S's EPS forecasts files do not have analyst names specified. I use the analyst ID to analyst name mapping from the recommendations files to map the analyst ID of the EPS forecasts to an analyst name.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_mapping = (recommendations.copy()\r\n",
    "                   .filter(['analyst', 'analyst_id', 'ticker'])\r\n",
    "                   .drop_duplicates(['analyst_id', 'ticker'])\r\n",
    "                   .reset_index(drop=True))\r\n",
    "                   \r\n",
    "analyst_mapping.to_feather(os.path.join(pipeline, 'store', 'analyst_mapping.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match analyst's rating with conference calls transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pd.read_feather(os.path.join('2_pipeline', '02-02_conference_calls_preprocess', 'out', 'cc_transcripts.feather'))\r\n",
    "cc = (cc.filter(['gvkey', 'ticker', 'event_date', 'speaker_name', 'speaker_firm', 'speaker_role'])\r\n",
    "        .query(\"speaker_role == 'Analyst'\")\r\n",
    "        .drop_duplicates()\r\n",
    "        .reset_index(drop=True))\r\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "6568"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge to transcripts\r\n",
    "recommendations_cc = (recommendations.merge(cc,\r\n",
    "                                            left_on=['ticker', 'analyst'],\r\n",
    "                                            right_on=['ticker', 'speaker_name'],)\r\n",
    "                                     .assign(days_between=lambda x: x['date'] - x['event_date'])\r\n",
    "                                     .query('0 <= days_between.dt.days <= 20')\r\n",
    "                                     .sort_values(['gvkey', 'analyst', 'brokerage', 'date', 'days_between'])\r\n",
    "                                     .drop_duplicates(['gvkey', 'analyst', 'brokerage', 'date'], keep='first'))\r\n",
    "\r\n",
    "len(recommendations_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations sentiment by analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_sentiment_analyst = (recommendations_cc\r\n",
    "                                     .copy()\r\n",
    "                                     .reset_index(drop=True)\r\n",
    "                                     .filter(['gvkey', 'event_date', 'analyst', 'rating_change', 'rating_sentiment']))\r\n",
    "recommendations_sentiment_analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_sentiment_analyst.to_feather(os.path.join(pipeline, 'out', 'recommendations_analyst.feather'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ad8bff83ca7a203c8f5c1f2f3a00576dbcaaca98e752b3367803050219b2dc1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('ccs': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}