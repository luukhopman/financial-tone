{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyst Price Target\r\n",
    "*[Source](https://wrds-web.wharton.upenn.edu/wrds//ds/ibes/ptgdet/index.cfm)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = '06-02_analysts_price_target'\r\n",
    "PROJECT = 'conference-calls-sentiment'\r\n",
    "PYTHON_VERSION = '3.7.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import re\r\n",
    "import numpy as np\r\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = re.sub(\"(?<={})[\\w\\W]*\".format(PROJECT), \"\", os.getcwd())\r\n",
    "os.chdir(workdir)\r\n",
    "\r\n",
    "pipeline = os.path.join('2_pipeline', NAME)\r\n",
    "if not os.path.exists(pipeline):\r\n",
    "    os.makedirs(pipeline)\r\n",
    "    for folder in ['out', 'store', 'tmp']:\r\n",
    "        os.makedirs(os.path.join(pipeline, folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Main Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {'OFTIC': 'ticker', 'TICKER': 'ibes_ticker', 'CNAME': 'coname',\r\n",
    "        'ESTIMID': 'brokerage', 'ALYSNAM': 'analyst', 'VALUE': 'value',\r\n",
    "        'AMASKCD': 'analyst_id', 'ANNDATS': 'date', 'ANNTIMS': 'time'}\r\n",
    "\r\n",
    "price_target_raw = pd.read_csv(os.path.join('0_data', 'ibes', 'ibes_price-target_2000-2020.csv.gz'), usecols=cols, encoding='latin-1')\r\n",
    "\r\n",
    "price_target_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_previous_valuation(df):\r\n",
    "    df[['prev_value', 'prev_date']] = df.groupby(['ticker', 'analyst_id'])[['value', 'date']].shift(1)\r\n",
    "    df['days_since_prev'] = df['date'] - df['prev_date']\r\n",
    "    df['price_change'] = df['value'] - df['prev_value']\r\n",
    "    df['price_sentiment'] = np.where(df['price_change'] > 0, 1, -1)\r\n",
    "    df['price_sentiment'] = np.where(df['price_change'] == 0, 0, df['price_sentiment'])\r\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_target = (price_target_raw\r\n",
    "                .copy()\r\n",
    "                .dropna()\r\n",
    "                .rename(columns=cols)\r\n",
    "                .assign(\r\n",
    "                    date=lambda x: pd.to_datetime(x['date'], format=r'%Y%m%d'),\r\n",
    "                    analyst=lambda x: x['analyst'].apply(lambda a: ' '.join(a.split()))  # Remove extra whitespaces between analyst names\r\n",
    "                    )\r\n",
    "                .sort_values(['ticker', 'analyst_id', 'date', 'time'])\r\n",
    "                .drop_duplicates(['ticker', 'analyst_id', 'date'])\r\n",
    "                .pipe(add_previous_valuation)\r\n",
    "                .dropna()\r\n",
    "                .reset_index(drop=True)\r\n",
    "                .filter(['ticker', 'coname', 'brokerage', 'brokarage_id',\r\n",
    "                         'analyst', 'analyst_id', 'date', 'days_since_prev',\r\n",
    "                         'prev_value', 'value', 'price_change', 'price_sentiment']))\r\n",
    "\r\n",
    "price_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save `analyst_id`-`analyst` mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_mapping = (price_target.copy()\r\n",
    "                   .filter(['analyst', 'analyst_id', 'ticker'])\r\n",
    "                   .drop_duplicates(['analyst_id', 'ticker'])\r\n",
    "                   .reset_index(drop=True))\r\n",
    "                   \r\n",
    "analyst_mapping.to_feather(os.path.join(pipeline, 'store', 'analyst_mapping.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match analyst's rating with conference calls transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pd.read_feather(os.path.join('2_pipeline', '02-02_conference_calls_preprocess', 'out', 'cc_transcripts.feather'))\r\n",
    "cc = (cc.filter(['gvkey', 'ticker', 'event_date', 'speaker_role', 'speaker_name', 'speaker_firm'])\r\n",
    "        .query(\"speaker_role == 'Analyst'\")\r\n",
    "        .drop_duplicates()\r\n",
    "        .reset_index(drop=True))\r\n",
    "cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to transcripts\r\n",
    "price_target_cc = (price_target.merge(cc,\r\n",
    "                                      left_on=['ticker', 'analyst'],\r\n",
    "                                      right_on=['ticker', 'speaker_name'])\r\n",
    "                               .assign(days_between=lambda x: x['date'] - x['event_date'])\r\n",
    "                               .query('0 <= days_between.dt.days <= 20')\r\n",
    "                               .sort_values(['gvkey', 'analyst', 'brokerage', 'date', 'days_between'])\r\n",
    "                               .drop_duplicates(['gvkey', 'analyst', 'brokerage', 'date'], keep='first'))\r\n",
    "\r\n",
    "len(price_target_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations sentiment by analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_target_sentiment_analyst = (price_target_cc\r\n",
    "                                  .copy()\r\n",
    "                                  .reset_index(drop=True)\r\n",
    "                                  .filter(['gvkey', 'event_date', 'analyst', 'price_change', 'price_sentiment']))\r\n",
    "price_target_sentiment_analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_target_sentiment_analyst.to_feather(os.path.join(pipeline, 'out', 'price_level_analyst.feather'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ad8bff83ca7a203c8f5c1f2f3a00576dbcaaca98e752b3367803050219b2dc1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('ccs': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}