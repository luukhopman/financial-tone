{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyst EPS Forecast\r\n",
    "*[Source](https://wrds-web.wharton.upenn.edu/wrds//ds/ibes/det/index.cfm)*\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = '06-03_analysts_eps_forecast'\r\n",
    "PROJECT = 'conference-calls-sentiment'\r\n",
    "PYTHON_VERSION = '3.7.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import re\r\n",
    "import numpy as np\r\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = re.sub(\"(?<={})[\\w\\W]*\".format(PROJECT), \"\", os.getcwd())\r\n",
    "os.chdir(workdir)\r\n",
    "\r\n",
    "pipeline = os.path.join('2_pipeline', NAME)\r\n",
    "if not os.path.exists(pipeline):\r\n",
    "    os.makedirs(pipeline)\r\n",
    "    for folder in ['out', 'store', 'tmp']:\r\n",
    "        os.makedirs(os.path.join(pipeline, folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Main Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {'OFTIC': 'ticker', 'TICKER': 'ibes_ticker', 'CNAME': 'coname',\r\n",
    "        'ESTIMATOR': 'brokerage_id', 'VALUE': 'eps_forecast',\r\n",
    "        'ANALYS': 'analyst_id', 'ANNDATS': 'date', 'ANNTIMS': 'time'}\r\n",
    "\r\n",
    "eps_forecast_raw = pd.read_csv(os.path.join('0_data', 'ibes', 'ibes_eps-forecast_2000-2020.csv.gz'), usecols=cols, encoding='latin-1')\r\n",
    "\r\n",
    "eps_forecast_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_previous_valuation(df):\r\n",
    "    df[['prev_forecast', 'prev_date']] = df.groupby(['ticker', 'analyst_id'])[['eps_forecast', 'date']].shift(1)\r\n",
    "    df['days_since_prev'] = df['date'] - df['prev_date']\r\n",
    "    df['eps_change'] = df['eps_forecast'] - df['prev_forecast']\r\n",
    "    df['eps_sentiment'] = np.where(df['eps_change'] > 0, 1, -1)\r\n",
    "    df['eps_sentiment'] = np.where(df['eps_change'] == 0, 0, df['eps_sentiment'])\r\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_forecast = (eps_forecast_raw\r\n",
    "                .copy()\r\n",
    "                .rename(columns=cols)\r\n",
    "                .assign(date=lambda x: pd.to_datetime(x['date'], format=r'%Y%m%d'))\r\n",
    "                .sort_values(['ticker', 'analyst_id', 'date', 'time'])\r\n",
    "                .drop_duplicates(['ticker', 'analyst_id', 'date'])\r\n",
    "                .pipe(add_previous_valuation)\r\n",
    "                .dropna()\r\n",
    "                .reset_index(drop=True)\r\n",
    "                .filter(['ticker', 'coname', 'brokarage_id', 'analyst_id', 'date',\r\n",
    "                         'days_since_prev', 'prev_forecast', 'eps_forecast',\r\n",
    "                         'eps_change', 'eps_sentiment']))\r\n",
    "\r\n",
    "eps_forecast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map `analyst_id` to name\r\n",
    "*Add analyst name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_mapping = pd.read_feather(os.path.join('2_pipeline', '03-01_ibes_process_recommendations', 'store', 'analyst_mapping.feather'))\r\n",
    "eps_forecast_names = eps_forecast.merge(analyst_mapping, on=['analyst_id', 'ticker'])\r\n",
    "eps_forecast_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match analyst's forecast with conference calls transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pd.read_feather(os.path.join('2_pipeline', '02-02_conference_calls_preprocess', 'out', 'cc_transcripts.feather'))\r\n",
    "cc = (cc.filter(['gvkey', 'ticker', 'event_date', 'speaker_role', 'speaker_name', 'speaker_firm'])\r\n",
    "        .query(\"speaker_role == 'Analyst'\")\r\n",
    "        .drop_duplicates()\r\n",
    "        .reset_index(drop=True))\r\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "130738"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge to transcripts\r\n",
    "eps_forecast_cc = (eps_forecast_names.merge(cc,\r\n",
    "                                            left_on=['ticker', 'analyst'],\r\n",
    "                                            right_on=['ticker', 'speaker_name'])\r\n",
    "                                     .assign(days_between=lambda x: x['date'] - x['event_date'])\r\n",
    "                                     .query('0 <= days_between.dt.days <= 20')\r\n",
    "                                     .sort_values(['gvkey', 'analyst', 'speaker_firm', 'date', 'days_between'])\r\n",
    "                                     .drop_duplicates(['gvkey', 'analyst', 'speaker_firm', 'date'], keep='first'))\r\n",
    "\r\n",
    "len(eps_forecast_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPS forecast sentiment by analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_forecast_sentiment_analyst = (eps_forecast_cc\r\n",
    "                                  .copy()\r\n",
    "                                  .reset_index(drop=True)\r\n",
    "                                  .filter(['gvkey', 'event_date', 'analyst', 'eps_change', 'eps_sentiment']))\r\n",
    "eps_forecast_sentiment_analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_forecast_sentiment_analyst.to_feather(os.path.join(pipeline, 'out', 'eps_forecast_analyst.feather'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ad8bff83ca7a203c8f5c1f2f3a00576dbcaaca98e752b3367803050219b2dc1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('ccs': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}