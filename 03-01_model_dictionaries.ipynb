{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = '03-01_model_dictionaries'\r\n",
    "PROJECT = 'conference-calls-sentiment'\r\n",
    "PYTHON_VERSION = '3.7.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import re\r\n",
    "import pickle\r\n",
    "import numpy as np\r\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = re.sub(\"(?<={})[\\w\\W]*\".format(PROJECT), \"\", os.getcwd())\r\n",
    "os.chdir(workdir)\r\n",
    "\r\n",
    "pipeline = os.path.join('2_pipeline', NAME)\r\n",
    "if not os.path.exists(pipeline):\r\n",
    "    os.makedirs(pipeline)\r\n",
    "    for folder in ['out', 'store', 'tmp']:\r\n",
    "        os.makedirs(os.path.join(pipeline, folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "# Main Code\r\n",
    "## IV-4 Harvard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Positive: 1563\n",
      "# Negative: 1892\n"
     ]
    }
   ],
   "source": [
    "# Read general inquirer spreadsheet\r\n",
    "gi = pd.read_csv('http://www.wjh.harvard.edu/~inquirer/inqtabs.txt', sep='\\t', usecols=['Entry', 'Source', 'Positiv', 'Negativ'])\r\n",
    "\r\n",
    "iv4 = (gi.copy()\r\n",
    "         .loc[gi['Source'].isin(['H4Lvd', 'H4'])]\r\n",
    "         .assign(Entry=lambda x: x['Entry'].str.split('#').str[0].str.lower()\r\n",
    "         .drop_duplicates()))\r\n",
    "\r\n",
    "iv4_positive = list(iv4.loc[iv4['Positiv'] == 'Positiv', 'Entry'].dropna().unique())\r\n",
    "iv4_negative = list(iv4.loc[iv4['Negativ'] == 'Negativ', 'Entry'].dropna().unique())\r\n",
    "\r\n",
    "print(f\"# Positive: {len(iv4_positive)}\\n# Negative: {len(iv4_negative)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loughran & McDonald (2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Positive: 354\n",
      "# Negative: 2355\n"
     ]
    }
   ],
   "source": [
    "lm__dictionary = pd.read_csv(os.path.join('0_data', 'lm_dictionary', 'LoughranMcDonald_SentimentWordLists_2018.csv'))\r\n",
    "lm_positive = list(lm__dictionary['Positive'].str.lower().dropna().unique())\r\n",
    "lm_negative = list(lm__dictionary['Negative'].str.lower().dropna().unique())\r\n",
    "\r\n",
    "print(f\"# Positive: {len(lm_positive)}\\n# Negative: {len(lm_negative)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lists = [iv4_positive, iv4_negative, lm_positive, lm_negative]\r\n",
    "file_names = ['iv4_positive', 'iv4_negative', 'lm_positive', 'lm_negative']\r\n",
    "\r\n",
    "for sentiment_list, file_name in zip(sentiment_lists, file_names):\r\n",
    "    with open(os.path.join(pipeline, 'out', f'{file_name}.pickle'), 'wb') as f:\r\n",
    "        pickle.dump(sentiment_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('ccs': conda)",
   "name": "python370jvsc74a57bd04ad8bff83ca7a203c8f5c1f2f3a00576dbcaaca98e752b3367803050219b2dc1"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}